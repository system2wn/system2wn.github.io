---
layout: post
title:  Siamese系列模型性能对比
date:   2019-07-29 14:30:43 +0800
categories: 论文笔记
tag: 代码测试
---

* content
{:toc}

# 深入理解RPN网络

本文主要通过阅读Faster-RCNN原文，以及参考一些博文，对RPN网络进行深入的理解与总结。

## 1. 产生背景

### 1.1 Region Proposal（区域建议）

在介绍RPN之前必须要说明一个概念：区域建议，什么是区域建议呢？举个现实中的例子：就好比你现在想买部手机但是你不懂机器，那么多品牌和机型你不知道如何挑选，如果这个时候有一个很懂的朋友跟你推荐了几款，那么你就可以从这几款中去挑，这样大大节省了你单独挑的时间。这个思想就是现在神经网络中很流行的术语 **"注意力"机制**。在检测中使用区域建议方法，实际上就是在非常非常多的区域选择中，给检测器提出一些建议的区域，就是检测器该去重点看哪些区域，其他的区域可以不用去管了。

### 1.2 R-CNN（基于Region的CNN）

## 2. RPN（区域建议网络）

### 2.1 简介

RPN以任意大小的图片作为输入，然后输出一个矩形目标建议框的集合。将这个过程建模成一个全连接卷积网络，与Fast-RCNN共享一些公共的卷积层，比如使用VGG-16的话，会有13个共享卷积层。

要生成这些区域建议，我们在上述的共享卷积层的最后一层生成的卷积特征图上划动一个小网络。这个小网络是一个$n\times n$的空间窗口，每个窗口都会被映射成一个低维的特征。然后这个特征会输入到两个同级的全连接层——回归层$(reg)$和分类层$(cls)$。在faster-RCNN中设置$n=3$，实际上所有的空间位置都共享这个全连接层。所以整个结构可用一个$n\times n$的卷积层后跟两个同级的$1\times 1$的卷积层（$reg$和$cls$）构成。

![图1 RPN和anchors](/styles/images/2019-07-30-RPN/fig1.png)

### 2.1.1 Anchors

什么是Anchors呢？

在每个滑动窗口位置，我们都要同时预测多个区域建议，每个位置上最大的区域建议数量为$k$，所以$reg$层有$4k$个输出，对应着$k$个边界框的坐标，$cls$层有$2k$个输出分数，分别评估每个建议是object和不是object的概率。这k个建议由k个相关的边界框组成，称其为$anchors$。

实际上每个$anchors$就是以每个滑动窗口的中心为中心，并且与一个特定的scale和长宽比相关。默认情况下都有3个候选的scale和3个候选长宽比，因此每个滑动窗口位置都有$k=9$个$anchors$。

**Anchors的平移不变性**

$Anchors$的一个很重要的特点就是它的**平移不变性**，即：如果在图像上平移物体，相应的建议也应该平移，并且同样的方法应该可以在任意位置预测建议框。使用$anchors$可以保证这种平移不变性。对比MultiBox方法：使用k-means去生成800个anchors，这样不能保证平移不变性。所以当物体被平移了，MultiBox不能保证生成同样的建议。

不仅保证了平移不变性，这种使用$anchors$的方法，还可以减小模型的大小。对于VGG-16，大约有$512\times (4+2)\times 9=2.8\times 10^4$个参数，比MultiBox（$1536\times (4+1)\times 800=6.1\times 10^6$）少了两个数量级。

**Anchors的多尺度**

RPN中提出的Anchors给多尺度的表示提供了新的方法。传统的方法有：

1. **基于图像/特征金字塔：** 比如在DPM（Deformable parts models，2012年提出的一种目标检测算法）中，是将图像重新设置成许多scale的大小，然后特征图（HOG或者基于深度卷积提取的特征）使用每个不同scale的图像进行计算。这种方法确实是和有效的，但是很耗时。
2. **使用多尺度的滑动窗口：** 这种方法将卷积滤波器设置成多尺度的，即有很多个model，每种model对应不同尺寸的filter（比如$5\times 7$或者$7\times 5$），这些model分开进行训练。可以看成是一种”filter金字塔“，如下图所示：

![图2 filter金字塔](/styles/images/2019-07-30-RPN/fig2.png)

与上面的两种方法相比，RPN中的多尺度方法是基于**Anchors金字塔**的，非常高效并且节省成本。因为使用anchors boxes去进行分类和回归的话，图像/特征图只需要一个尺寸的，并且使用的filter也只有一个尺寸，只是在Anchors上有了多尺度。这样就很容易的在单一scale的图像上去使用卷积特征。

### 2.1.2 损失函数

训练RPN使用的label是一个二值label，即是（label为正）/不是（label为负）目标。其中label为正的anchors有两种：

1. 与一个ground-truth box有最高IoU值的anchor。IoU的定义大致如下图所示：
![图3 IoU示意图](/styles/images/2019-07-30-RPN/fig3.png)

2. 与任意ground-truth box的IoU值超过0.7的anchor。

这两个条件在某些情况下的重复的，比如最高的IoU值超过0.7。但是如果没有anchor的IoU值超过0.7的话，第2个条件就不成立了，所以我们仍然需要第一个条件的存在。

当一个非正anchor与所有ground-truth box的IoU都小于0.3时，我们将这个anchor的label设置为负。剩下的非正非负的anchor便不再参与训练，它们对训练过程没什么用。

在上述定义后，定义在一张图像上的损失函数为：

$$L(\{p_i\}, \{t_i\})=\frac{1}{N_{cls}}\sum_{i}L_{cls}(p_i,p_i^*)+\lambda\frac{1}{N_{reg}}\sum_i p_i^*L_{reg}(t_i,t_i^*)$$

其中$i$为一个mini-batch中anchor的索引，$p_i$为第$i$个anchor是目标的概率。$p_i^*$为anchor的标签，为1表示anchor为正，为0表示anchor为负。$t_i$为预测的边界框的向量表示（这里如果anchor为正的，我认为就是anchor的边界框坐标），包含四个坐标值。$t_i^*$为与正anchor相关的那个真实groud-truth box的边界框坐标。分类损失$L_{cls}$为是/不是目标的对数损失，回归损失$L_{reg}$定义为$L_{reg}(t_i,t_i^*)=R(t_i-t_i^*)$，其中$R$为smooth $L_1$损失。则式中的项$p_i^*L_{reg}$表示只有正anchor（$p_i^*=1$）才能激活这个项，负anchor的项不会计算。最终$cls$会输出$\{p_i\}$，$reg$会输出$\{t_i\}$。

损失函数中的分类和回归项分别使用$N_{cls}$和$N_{reg}$进行标准化，并使用一个平衡参数$\lambda$去平衡权重。