---
layout: post
title:  SiamRPN++论文笔记
date:   2019-07-24 16:10:43 +0800
categories: 论文笔记
tag: 论文笔记
---

* content
{:toc}

# SiamRPN++

## 1. Introduction

目前所有基于Siamese网络而做的跟踪网络backbone都使用的**8层的AlexNet**，这个浅层的网络肯定会在提取特征的能力上有所欠缺。也有研究人员做实验尝试使用深度的**ResNet**去替换Alex，但是发现性能并没有提升。而本文所做的工作就是进行一系列的改进，使得ResNet成功的在SiamRPN跟踪框架中work。

1. 文中提出了对运用深度网络后反而性能会下降的问题的分析，得出了深层网络会**破坏严格平移不变性**。
2. 文中提出了一种简单有效的采样策略去打破Siamese跟踪器的**空间不变性约束**，从而使得ResNet架构在Siamese跟踪器中work。
3. 对互相关操作提出了一种**多层特征聚合**的架构，通过使用多层特征去得到相似度图。
4. 通过分析Siamese网络结构，文中发现两个网络分支的参数数量是高度不均衡的，所以文中提出了一种**深度可分网络结构**，不仅可以减少模板分支的参数数量，还可以使整个模型的训练过程更加稳定。增强互相关性，生成与不同语义相关联的多组相似映射。

通过改进后，SiamRPN++在OTB2015、VOT2018、UAV123、LaSOT和TrackingNet五个数据集上达到了精确度最优，并且在作者的实验环境上跑到了35fps。作者还使用了稍微浅层的**MobileNet**作为backbone去训练，这样提升了跟踪速度，可以达到70fps，并且跟踪精度也十分可观。

## 2. Related work

目前最先进的跟踪算法就是相关滤波和深度学习的方法。相关滤波是从信号学的基础上发展来的，将跟踪问题看成一个在频率域上做模板匹配的互相关操作的过程，不仅精度高而且速度快。随着深度学习的发展，使用了深度特征的相关滤波算法逐渐成为了最先进的跟踪算法。

目前最近的是用Siamese网络来做跟踪，目前最先进的Siamese跟踪器使用RPN网络来提升性能同时加速跟踪，但是在OTB数据集上，性能还是和ECO、MDNet这些最先进的跟踪器存在差距。

在Siamese跟踪中都是使用AlexNet和VGG中的某些层，做浅层的特征提取跟踪，这种现象可以解释成浅层特征更适合于做跟踪。在本文中作者证明了使用深层网络可以更好的改善整个Siamese网络的性能。

## 3. Siamese Tracking with very deep networks

### 3.1 分析Siamese跟踪网络

基于Siamese网络的跟踪算法把跟踪问题视为一个互相关问题，从一个Siamese网络架构中学习深度模型，然后去进行相似特征图映射。两个分支中一个分支学习目标的特征表示，另一个分支学习搜索空间的表示。目标首先在第一帧中给出，表示为$z$，网络目的是在语义集成空间$\phi(\bullet)$中，从剩下的帧$x$里找到与模板最相似的图像patch：

$$f(z,x)=\phi(z)*\phi(x)+b$$

其中$b$对相似值的偏移量进行建模。

上述的Siamese跟踪器的算法很自然地表现出了两个跟踪器设计中的内在限制：

- 相似度匹配和特征提取都有一个**严格平移不变性**的内在限制(\f(z,x[\vartriangle\tau_j])=f(z,x)[\vartriangle\tau_j]\)，其中$[\triangle\tau_j]$是平移移位子窗口操作符，这个严格平移不变性保证了高效的跟踪和推理。

- 相似度匹配有一个**结构对称**的限制，举例来说就是$f(z,x')=f(x',z)$，以结构对称的方式设计网络非常适合于相似性学习。

上面的两个限制是影响深度网络用于Siamese跟踪器的主要原因。进一步讲，一个原因是使用深度网络会**破坏网络的严格平移不变性**，另一个原因是**使用RPN网络进行回归和分类需要不对称的特征**。对于第一个问题文中的解决办法是设计空间感知采样策略，第二个问题在3.4节中讨论。

严格平移不变性只存在于没有padding的网络中，也就是一些浅层网络，比如SiamRPN使用的修改过的AlexNet。但是padding在深层网络中是必须存在的，只有padding存在，网络才能做深而不会使特征完全丢失，但这样就会破坏Siamese跟踪网络中的严格平移不变性的限制。文中对于这个限制的假设是：**打破这个限制会带来空间偏差**。

所以对于上述限制，文中做了仿真实验，将带padding的深层网络作为Siamese跟踪器的backbone，定义shift（漂移）是一种数据增强方法，在均匀的分布中对样本进行平移的最大平移范围。然后进行了这样的实验：在三个分开进行的实验环境中，目标都位于图像中心，分别有三个漂移值（0,16,32）。然后使用这些数据分别网络直到收敛后，观察在测试集上的测试结果热力图，如下图所示：

![图1 使用三种shift分别对于的test数据集上的测试热力图结果](/styles/images/2019-07-24-SiamRPN++/fig1.png)

左图的shift值为0,可以看出在边界区域上的目标置信度几乎为0，即网络学习到了一个很强的中心偏移，而忽略了测试目标的表征特征；另外两张图都是带shift的，可以看出通过增加shift的范围可以防止模型陷入到这种中心化的解中。这个实验结果表明：使用shift范围为32的热力图结果更接近测试数据物体的位置分布。这样就证明了使用这种基于空间感知的采样策略可以有效的减轻因为使用了带padding的深层网络破坏了严格平移不变性限制所带来的不好的跟踪效果。

文中为了避免这种在目标物体上的中心偏移，使用了空间感知采样策略对backbone为ResNet50的SiamRPN进行了训练。下图为训练的表现结果：

![图2 使用空间感知采样策略训练了ResNet50 SiamRPN的表现](/styles/images/2019-07-24-SiamRPN++/fig2.png)

在$shift=0$的时候，网络在VOT2018上只有0.14的得分，随着shift的增加，网络的性能在不断变好，到大约$shift=64$的时候变得最好，这样也验证了采用中加入shift的重要性。

### 3.2 ResNet驱动的Siamese跟踪

在3.2小节中消除了中心偏移所带来的影响，这样就使得所有现成的网络（MoblieNet，ResNet等）都可以用到跟踪中来，并且我们可以自己去修改建立网络拓扑。在这一小节中主要讨论了**如果将一个深层网络应用到SiamRPN的跟踪算法中**，主要关注的还是ResNet50。常规的ResNet中存在32个像素的大stride，这样大的步长对于紧密的Siamese网络预测非常不适用。下图是文中设计的ResNet SiamRPN网络结构：

![图3 使用ResNet的SiamRPN网络结构](/styles/images/2019-07-24-SiamRPN++/fig3.png)

作者将$conv4$和$conv5$（即ResNet50的最后两个block）的步长由16和32全部设置成8，这样做一是使得最后两个block具有单位空间步长，二是通过扩张卷积来增加感受野。同时在每个block的输出位置加一个额外的$1\times1$的卷积层，用来将通道数降低到256。

因为所有层的padding都保留了，所以模板特征的空间大小增加到了15，这会给相关性计算模块带来沉重的计算负担。因此我们裁剪中间的$7\times7$的区域作为模板特征，其中每个特征单元仍然可以捕获整个目标区域（这里减小了计算负担，相当于做了一个加速的步骤）。

随后，我们将相关层和全卷积层融合成一个head module，用来计算分类分数（表示为$\mathcal{S}$）和回归边界框（表示为$\mathcal{B}$）。SiamRPN block表示为$\mathcal{P}$。

此外我们还发现如果对ResNet进行一些正确的微调，会提高跟踪性能。通过将ResNet的学习率设置为比RPN小10倍，提取出的特征更适合跟踪任务。与传统的Siamese跟踪方法不同，深度网络的参数是以端到端的形式进行联合训练。据作者所知，他们是第一个实现在视觉跟踪问题中使用深度Siamese网络（$>20$层）进行端到端的训练。

### 3.3 Layer-wise Aggregation（多层聚合）

我们认为视觉跟踪需要丰富的信息，比如层级从低到高、大小从小到大和分辨率从清晰到粗糙，这些信息都有会更利于跟踪。所以作者提出了将多个卷积层提取的特征进行融合的思想。这个思想也得益于深度网络中不同层提取的特征会有非常大的差异。ResNet中较浅的卷积层主要关注的是低层的信息，如颜色和形状，这在检测定位中是必不可少的信息，但是**缺乏语义信息**；深层的卷积层提取的特征**具有丰富的语义信息**，这些信息适用于一些具有挑战的场景比如运动模糊、巨大形变。使用这些**丰富的层次信息可能会有益于跟踪**。

所以在我们的实验中，使用多层特征来进行融合。对于ResNet50,我们分别使用**最后三个block**提取的三层特征去做多层特征聚合，定义这三层输出为$\mathcal{F}_3(z)$、$\mathcal{F}_4(z)$和$\mathcal{F}_5(z)$，如上面图3中所示，在$conv3$、$conv4$和$conv5$后面分别加一个SiamRPN模块。

由于三个RPN模块的输出分辨率相同，所以直接采用加权和的方式进行输出融合：

$$\mathcal{S}_{all}=\sum_{l=3}^{5}\alpha_l*\mathcal{S}_l，\mathcal{B}_{all}=\sum_{l=3}^{5}\beta_l*\mathcal{B}_l$$

> 这个公式文中的$\alpha$和$\beta$下标是i，我觉得他写错了，应该是l

分类和回归的权重是不同的，因为他们关注的区域不同，这个权重也是随着网络的训练进行端到端的离线优化的。并且在这部分优化中，并没有直接对卷积层提取的特征进行融合，而是对不同层的特征分开做了分类和回归，对结果进行融合。这样使用深度网络做backbone获得了非常显著的提升。

### 3.4 Depthwise Cross Correlation（深度相关操作）

相关模块是将**两个分支（template分支和detection分支）的信息进行融合**。在SiamFC中使用交叉相关层去获得关于目标位置的单通道响应图。在SiamRPN中，通过**使用一个大的卷积层来进行通道扩张（UP-Xcorr，即升维）**，将相关层进行扩展来集成更高层信息，如anchors。但是这个通道提升模块使得网络的参数分布变得十分不平衡（如RPN模块中包含20M的参数，但是特征提取层只有4M），这会让SiamRPN的训练优化变得很困难。

所以在这里作者提出了一个轻量的交叉相关层：**Depthwise Cross Correlation深度相关(DW-XCorr)** 去实现高效的信息关联。DW-XCorr层的参数比UP-XCorr少了10倍，同时性能与其相当。三种相关模块的对比如下图所示：

![图4 三种相关模块的对比](/styles/images/2019-07-24-SiamRPN++/fig4.png)

为了实现DW-XCorr，这里使用了一个**conv-bn块**，用于调整从每个剩余块中提取出的特征，以适应跟踪任务。在SiamRPN的相关模块中，回归框的预测和基于anchors的分类是完全不同的两种操作，所以**模块是不对称的**，这与SiamFC中的对应模块是存在差异的。为了编码这种差异，我们将模板分支和搜索分支分别通过两个不共享的卷积层。然后将生成的两个具有相同通道数的特征图进行通道间的相关操作。然后再加入一个**conv-bn-relu块**，用来**融合不同通道的输出**。最后增加一个卷积层用于输出分类和回归结果。如下图所示：

![图5 DW-XCorr模块](/styles/images/2019-07-24-SiamRPN++/fig5.png)

换成DW-XCorr模块后，大大降低了计算耗损和空间使用量。并且模板分支和搜索分支的参数数量也得到了平衡，从而使跟踪结果更加稳定。

文中还提到了一个非常有趣的现象，如下图所示：

![图6 同一类别的目标往往在同一个通道上有高的响应，而在别的通道上的响应受到抑制](/styles/images/2019-07-24-SiamRPN++/fig6.png)

同一类别的目标往往在同一个通道上有高的响应，而在别的通道上的响应受到抑制（如car在第148个通道上响应值最大、person在222，、face在226）。这个特点可以这样去理解：**深度相关操作产生的通道特征是近乎正交的**，并且每个通道都表示了一些语义信息。我们也对升通道相关操作产生的热力图进行了分析，生成的响应图的可解释性就相对较差了。

## 4. 实验结果

### 4.1 训练集和模型评估

- **训练：** 网络中的backbone是在ImageNet上预训练好的，然后整个网络在COCO、ImageNet DET、ImageNet VID和YouTube-BoundingBoxes Dataset上 训练的，学习一个如何在跟踪中衡量目标间的相似性的一般概念。在训练和测试过程中，都使用127像素的模板样本和255像素的search region。

- **评估：** 主要使用OTB2015、VOT2018和UAV123这些短时跟踪数据集进行评估。同时也使用VOT2018-LT去进行长时间跟踪的评估。同时还使用了目前最新的两个跟踪数据集LaSOT和TrackingNet进行测试。

### 4.2 实现细节

- **网络架构上：** 训练和推理过程设置都与DaSiamRPN相同，同时在经过stride-reduced处理的ResNet-50后面连接两个兄弟卷积层去做proposal的分类和边界框回归。并且在$conv3$、$conv4$、$conv5$三个block后面都连接一个随机初始化的$1\times1$的卷积层，用来将特征维度降低到256。

- **优化上：** SiamRPN++使用SGD作为优化算法。在8块GPU上使用同步SGD，一个minibatch为128个图像对（即每个GPU16对），训练到收敛一共耗费12个小时。在训练RPN分支时，先进行了5轮预热训练，学习率为0.001.然后在最后的15轮训练中，整个网络进行端到端的训练，学习率从0.005到0.0005进行指数性的下降。权重衰减值为0.00005，动量设置为0.9（这里的动量就把SGD的下降当成了一个从斜坡滚下的小球一样，它会有一定的动量向反坡方向上升，这样可以避免一定情况下陷入了局部最优解的情况）。训练损失函数为分类损失和回归的standard smooth $L_1$损失之和。

### 4.3 分开实验

- **backbone：** 实验比较了不同的backbone对于跟踪结果的影响，下图显示了分别使用AlexNet、ResNet-18、ResNet-34,ResNet-50和MobileNet-v2做backbone的性能表现：

![图7 使用不同backbone的跟踪性能表现](/styles/images/2019-07-24-SiamRPN++/fig7.png)

使用的评测指标是Area Under Curve（AUC）。

下图阐述了将AlexNet换成ResNet-50后的性能提升（在VOT2018数据集上）。并且这个结果也显示出了微调backbone部分的重要性：

![图8 换成ResNet-50后的性能提升表现](/styles/images/2019-07-24-SiamRPN++/fig8.png)

- **多层特征聚合：** 实验调研多层特征聚合会带来的影响。首先我们分别对ResNet-50的三个block加一个单独的RPN，然后发现在$conv4$上单独跑得Expected Average Overlap（EAO）指数为0.374，而更深层的和更浅层的性能都会下降大概4个百分点。通过对其中的两层进行融合，$conv4$和$conv5$的融合提升了性能，但那是另外两个融合并没有提升性能。但尽管如此，在跟踪的鲁棒性上还是提升了10%，这也是我们的跟踪器的关键弱点。说明这个跟踪器还有上升空间。当融合了三层后，精度和鲁棒性都得到了进一步提升。

- **深度相关：** 将UP-XCorr和DW-XCorr进行对比， 如上面那张图所示，DW-XCorr提升了性能，证明了DW-XCorr的重要性，说明了两个分支的参数均衡分布使得学习过程更加稳定，收敛性更好。

### 4.4 对比最先进算法

SiamRPN++在多个数据集上都达到了目前最先进的表现，并且在文中在Titan Xp GPU上跑的速度可以达到35fps，通过使用MobileNet和ResNet-18，速度可以达到超过70fps，并且性能下降很小，下面的图片显示了SiamRPN++在各种数据集上的性能评测：

![图9 OTB2015数据集上的最先进算法评测](/styles/images/2019-07-24-SiamRPN++/fig9.png)

![图10 VOT2018上的EAO指数表现](/styles/images/2019-07-24-SiamRPN++/fig10.png)

![图11 VOT2018上的精确度和速度表现对比](/styles/images/2019-07-24-SiamRPN++/fig11.png)

![图12 长时间跟踪表现](/styles/images/2019-07-24-SiamRPN++/fig12.png)

![图13 UAV123上的评测表现](/styles/images/2019-07-24-SiamRPN++/fig13.png)

![图14 LaSOT评测表现](/styles/images/2019-07-24-SiamRPN++/fig14.png)

![图15 TrackingNet上的评测结果](/styles/images/2019-07-24-SiamRPN++/fig15.png)